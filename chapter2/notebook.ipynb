{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 自然言語処理と単語の分散表現\n",
    "\n",
    "この本では、自然言語処理として、（言葉の意味の最小単位である）単語の意味をコンピュータに理解させる方法として、以下の３つの方法を見ていく。\n",
    "\n",
    "* シソーラスによる手法\n",
    "* カウントベースによる手法\n",
    "* 推論ベースの手法（word2vec) → ３章\n",
    "\n",
    "## 2.2 シソーラス\n",
    "\n",
    "シソーラスとは、基本的には類語辞書で、同義語や類義語が同じグループに分類される辞書で、以下の特徴を持つ。\n",
    "\n",
    "* 人の手でメンテナンスされる辞書。\n",
    "* 例えば、`car ` = `auto` `automobile` `machine` `motorcar` のよう同義語を得ることができる。\n",
    "* 単語間で、「上位と下位」、「全体と部分」などの、関連性が定義されていることがある。例えば、carの場合\n",
    "\n",
    "![relation](https://raw.githubusercontent.com/aha-oretama/deep-learning-from-scratch-2/master/chapter2/image/thesaurus.png)\n",
    "\n",
    "このようにすべての単語に対して、類義語の集合を作り、それぞれの単語の関係をグラフで表現することで、単語間のつながりを定義できる。  \n",
    "これは、コンピュータに単語の意味を（間接的にであれ）授けることができたと言える。\n",
    "\n",
    "### 2.2.1 WordNet\n",
    "\n",
    "自然言語処理の分野で、最も有名なシソーラスはWordNetであり、NLTKに入っている。  \n",
    "http://www.nltk.org/howto/wordnet.html\n",
    "\n",
    "ただの辞書なので動作は割愛。実際の動作は付録B参照。\n",
    "\n",
    "### 2.2.2 シソーラスの問題点\n",
    "\n",
    "人の手でメンテナンスされるもののため、以下の問題点が存在する。\n",
    "\n",
    "* 時代の変化に対応するのが困難  \n",
    "→ 言葉は時とともに変化する。\n",
    "* 人の作業コストが高い\n",
    "* 単語のニュアンスを表現できない  \n",
    "→ ex. ヴィンテージとレトロ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 カウントベースの手法\n",
    "\n",
    "\n",
    "コーパス → 分布仮説からの共起行列 → コサイン類似度 → 相互情報量 → 次元削減という流れ。  \n",
    "また１文からなる単純なテキスト → 実践的なコーパスという流れ。\n",
    "\n",
    "### 2.3.1 コーパスの下準備\n",
    "\n",
    "コーパスとは、自然言語処理の研究やアプリケーションのために目的をもって収集された大量のテキストデータ。  \n",
    "以降は、まず`You say goodbye and I say hello.`という文を対象として、処理を行っていく。ここでは、下準備処理を行う。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 1 5 6]\n",
      "{'you': 0, 'say': 1, 'goodbye': 2, 'and': 3, 'i': 4, 'hello': 5, '.': 6}\n",
      "{0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello', 6: '.'}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = text.replace('.',' .')\n",
    "    words = text.split(' ')\n",
    "    \n",
    "    word_to_id = {}\n",
    "    id_to_word = {}\n",
    "    for word in words:\n",
    "        if word not in word_to_id:\n",
    "            new_id = len(word_to_id)\n",
    "            word_to_id[word] = new_id\n",
    "            id_to_word[new_id] = word\n",
    "    \n",
    "    corpus = np.array([word_to_id[w] for w in words])\n",
    "    \n",
    "    return corpus, word_to_id, id_to_word\n",
    "\n",
    "text = 'You say goodbye and I say hello.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "\n",
    "print(corpus) ## 単語IDのリスト  \n",
    "print(word_to_id) ## 単語から単語IDへのディクショナリ \n",
    "print(id_to_word) ## 単語IDから単語へのディクショナリ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2 単語の分散表現\n",
    "\n",
    "自然言語処理で、単語を（色のRGBのような）ベクトル表現で行うことができれば、定量化が簡単に行える。  \n",
    "単語のベクトルを、単語の分散表現と呼ぶ。\n",
    "\n",
    "### 2.3.3 分布仮説\n",
    "\n",
    "自然言語処理の歴史において、単語をベクトルで表す研究は数多く行われてきた。そのほどんどすべてが、「単語の意味は、周囲の単語によって形成される」という、分布仮説に呼ばれるもの。  \n",
    "つまり、単語の意味はその単語のコンテキスト（文脈）によって、単語の意味が形成されるということ。\n",
    "\n",
    "ex.   \n",
    "「I drink beer」「We drink wine」  \n",
    "「I guzzle beer」「We　guzzle wine」  \n",
    "guzzle: がぶがぶ飲む\n",
    "\n",
    "この本では、以下のように定義している。\n",
    "\n",
    "コンテキスト： ある中央の単語に対して、その周囲にある単語\n",
    "ウィンドウサイズ： 周囲の単語をどれだけ含めるか\n",
    "\n",
    "![context](https://raw.githubusercontent.com/aha-oretama/deep-learning-from-scratch-2/master/chapter2/image/context.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.4 共起行列\n",
    "\n",
    "カウントベースでは、周囲の単語をカウントすることで、ベクトルを表現する。  \n",
    "具体的にはある単語に着目した場合、その周囲にどのような単語がどれだけ現れるのかをカウントし、それを集計する。\n",
    "\n",
    "\n",
    "|  --| you | say | goodbye | and | i | hello | . |\n",
    "|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|\n",
    "| you | 0 | 1 | 0 | 0 | 0 | 0 | 0 |\n",
    "| say | 1 | 0 | 1 | 0 | 1 | 1 | 0 |\n",
    "| goodbye | 0 | 1 | 0 | 1 | 0 | 0 | 0 |\n",
    "| and | 0 | 0 | 1 | 0 | 1 | 0 | 0 |\n",
    "| i | 0 | 1 | 0 | 1 | 0 | 0 | 0 |\n",
    "| hello | 0 | 1 | 0 | 0 | 0 | 0 | 1 |\n",
    "| . | 0 | 0| 0 | 0 | 0 | 1 | 0 |\n",
    "\n",
    "上記の共起行列をプログラミングで自動で作成する関数を作成する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 0 0 0 0]\n",
      " [1 0 1 0 1 1 0]\n",
      " [0 1 0 1 0 0 0]\n",
      " [0 0 1 0 1 0 0]\n",
      " [0 1 0 1 0 0 0]\n",
      " [0 1 0 0 0 0 1]\n",
      " [0 0 0 0 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# vocab_size: 語彙数\n",
    "def create_to_matrix(corpus, vocab_size, window_size=1):\n",
    "    corpus_size = len(corpus)\n",
    "    co_matrix = np.zeros((vocab_size, vocab_size), dtype=np.int32)\n",
    "    \n",
    "    for idx, word_id in enumerate(corpus):\n",
    "        for i in range(1, window_size+1):\n",
    "            left_idx = idx - i\n",
    "            right_idx = idx + i\n",
    "            \n",
    "            if left_idx >= 0:\n",
    "                left_word_id = corpus[left_idx]\n",
    "                co_matrix[word_id, left_word_id] += 1\n",
    "                \n",
    "            if right_idx < corpus.size:\n",
    "                right_word_id = corpus[right_idx]\n",
    "                co_matrix[word_id, right_word_id] += 1\n",
    "                \n",
    "    return co_matrix\n",
    "        \n",
    "co_matrix = create_to_matrix(corpus, len(word_to_id))\n",
    "\n",
    "print(co_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.5 ベクトル間の類似度\n",
    "\n",
    "単語のベクトル表現の類似度に関しては、コサイン類似度がよく用いられる。\n",
    "\n",
    "```\n",
    "similarity(x,y) = x・y / ||x|| ||y|| = x1y1 + ... + xnyx / √ x1^2 + ... xn^2 √ y1^2 + ... yn ^2\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
